{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import preprocessing\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing.Preprocessing.load_df('/Users/cm/PycharmProjects/week_program/data/M_data_2019_04_16','train climateschlafzimmer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_updated'] = df['last_updated'].astype(np.datetime64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = np.datetime64('2019-04-02 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['last_updated'] > start_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-383-6f9a9d6ac462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_updated'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "dates = matplotlib.dates.date2num(train_set['last_updated'])\n",
    "fig1 = matplotlib.pyplot.figure(figsize=[20,10])\n",
    "plt.plot_date(dates, train_set[0], '-')\n",
    "plt.plot_date(dates, train_set[1], '-')\n",
    "plt.plot_date(dates, train_set[2], '-')\n",
    "plt.plot_date(dates, train_set[3], '-')\n",
    "#matplotlib.pyplot.plot_date(dates, frame3['wind_direction'], '-')\n",
    "#matplotlib.pyplot.plot_date(dates, frame3['humidity'], '-')\n",
    "#matplotlib.pyplot.plot_date(dates, df['cloudiness'], '-')\n",
    "#matplotlib.pyplot.plot_date(dates, frame3['pressure'], '-')\n",
    "#matplotlib.pyplot.plot_date(dates, frame3['dewpoint_temperature'], '-')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more daily forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mseabs\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out):\n",
    "    # flatten data\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end < len(data):\n",
    "            x_input = data[in_start:in_end,1:]\n",
    "            #x_input = x_input.reshape((len(x_input), x_input.shape[1]))\n",
    "            X.append(x_input)\n",
    "            y.append(data[in_end:out_end,0])\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14390 1439 1439\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set, test_set = train.train_val_test_split(df, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1439, 18)\n",
      "(1, 1439, 18)\n",
      "(1, 1439, 18)\n"
     ]
    }
   ],
   "source": [
    "# validate train data\n",
    "print(train_set.shape)\n",
    "#print(train_set[0, 0, 0], train_set[-1, -1, 0])\n",
    "# validate test\n",
    "print(test_set.shape)\n",
    "#print(test_set[0, 0, 0], test_set[-1, -1, 0])\n",
    "print(val_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_day = 320#1440\n",
    "learning_rate = 0.005\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = to_supervised(train_set,batch_size,samples_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = to_supervised(val_set,batch_size,samples_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = to_supervised(test_set,batch_size,samples_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13750, 320, 17)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13750, 320)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN - LSTM\n",
    "class Lstm(nn.Module):\n",
    "    def __init__(self, d_in , hidden_dim, d_out):\n",
    "        super(Lstm, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "\n",
    "        self.lstm = nn.LSTM(self.d_in, self.hidden_dim)\n",
    "        self.out = nn.Linear(self.hidden_dim, self.d_out)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, batch_size, self.hidden_dim),\n",
    "                torch.zeros(1, batch_size, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, cell_input):\n",
    "        lstm_out, self.hidden = self.lstm(cell_input, self.hidden)\n",
    "        score = self.out(lstm_out)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = train_set.drop(columns=['current_temp','last_updated'])\n",
    "#y_train = train_set['current_temp']\n",
    "#X_val = val_set.drop(columns=['current_temp','last_updated'])\n",
    "#y_val = val_set['current_temp']\n",
    "#X_test = test_set.drop(columns=['current_temp','last_updated'])\n",
    "#y_test = test_set['current_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X_train).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v = torch.from_numpy(X_val).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = torch.from_numpy(X_test).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13750, 320, 17]) (799, 320, 17) (799, 320, 17)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_val.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "#X = X / float(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(y_train).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_v = torch.from_numpy(y_val).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = torch.from_numpy(y_test).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13750, 320])"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularisierung\n",
    "weight_decay=0.0\n",
    "\n",
    "# the model\n",
    "hidden_dim = 64\n",
    "features = X.shape[2]\n",
    "model = Lstm(features, hidden_dim, d_out=1)\n",
    "N = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADAM\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "outputs= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "epochs = range(n_epochs)\n",
    "idx = 0\n",
    "\n",
    "for t in epochs:\n",
    "    start = time.time()      \n",
    "    #or batch in range(0, int(N/batch_size)+1):\n",
    "    #   if(batch<int(N/batch_size)):\n",
    "    #   # Step 1. Calculate Batch\n",
    "    #       batch_x = X[batch * batch_size : (batch + 1) * batch_size, :,:]  \n",
    "    #       # convert to: sequence x batch_size x n_features \n",
    "    #       #batch_x = batch_x.reshape(batch_size, samples_per_day, features)#.transpose(0,1)  \n",
    "    #       batch_y = y[batch * batch_size : (batch + 1) * batch_size] \n",
    "    #       \n",
    "    #       #print(X.shape, batch_x.shape, batch_y.shape)\n",
    "    #   else:\n",
    "    #       batch_x = X[(batch - 1) * batch_size +(N % batch_size): batch * batch_size + (N % batch_size), :]   \n",
    "    #       # convert to: sequence x batch_size x n_features \n",
    "    #       #batch_x = batch_x.reshape(batch_size, samples_per_day, features).transpose(0,1)        \n",
    "    #       batch_y = y[(batch - 1) * batch_size + (N % batch_size): (batch + 1) * batch_size + (N % batch_size)]    # Step 2. Remember that Pytorch accumulates gradients.\n",
    "    \n",
    "    # We need to clear them out before each instance\n",
    "    model.zero_grad()\n",
    "        \n",
    "    # Also, we need to clear out the hidden state of the LSTM,\n",
    "    # detaching it from its history on the last instance.\n",
    "    model.hidden = model.init_hidden(batch_size)\n",
    "    \n",
    "    # Step 3. Run our forward pass.\n",
    "    output = model(X)\n",
    "    #outputs.append(output)\n",
    "    # Step 4. Berechne den Fehler mit dem letzten output \n",
    "    loss = criterion(output[-1,:,-1], batch_y[-1,:])\n",
    "    #print(output.shape, batch_y.shape)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Berechne den Fehler (Ausgabe des Fehlers alle 100 Iterationen)\n",
    "    if t % 1 == 0:\n",
    "        loss_hist.append(loss.item())\n",
    "        print(t, loss.item(), time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_hist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "new_val = []\n",
    "for items in range(output.shape[0]):\n",
    "    dff = batch_y.numpy()\n",
    "    new_val.append(output[items,:,-1].detach().mean())\n",
    "    #print(dff[items])\n",
    "    #np.append(dff,new_val)\n",
    "    #plt.plot(output[items,:].detach().numpy());\n",
    "    #plt.plot(dff);\n",
    "    plt.figure(1, figsize=(16, 300))\n",
    "    plt.subplot(output.shape[0]//2,2,items+1)\n",
    "    plt.plot(dff[items])\n",
    "    plt.plot(output[items,:,-1].detach().numpy());\n",
    "    plt.legend(['real','predicted']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.plot(outputs);\n",
    "   # plt.plot(batch_y.numpy()[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output[-1,:,-1].detach().numpy());\n",
    "plt.plot(batch_y[-1,:].numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.6000]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[-1,:,-1].detach().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = model(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_forecasts(y_test, output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
